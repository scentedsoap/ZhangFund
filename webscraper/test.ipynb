{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/1018840/000101884023000011/anf-20230128.htm#iae6813e7b5b64dc181610919df178cf4_73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import copy\n",
    "import requests\n",
    "import webscraper as ws\n",
    "\n",
    "class AnnualReport:\n",
    "\n",
    "  \"\"\"\n",
    "  Resembles An Annual Report (Form 10K) That Is Filed By Companies To SEC. \n",
    "  \n",
    "  An annual report has the following structure:\n",
    "\n",
    "      Part 1\n",
    "\n",
    "          Item 1: Business\n",
    "            Item 1A: Risk Factors\n",
    "            Item 1B: Unresolved Staff Comments\n",
    "          Item 2: Properties\n",
    "          Item 3: Legal Proceedings\n",
    "          Item 4: ???\n",
    "          \n",
    "      Part 2\n",
    "\n",
    "          Item 5: Market, Stockholder, and Repurchasing\n",
    "          Item 6: Selected Financial Data\n",
    "          Item 7: MD&A\n",
    "            Item 7A: Quantitative and Qualitative Disclosures about Market Risk\n",
    "          Item 8: Financial Statements and Supplementary Data\n",
    "          Item 9: Changes in and Disagreements with Accountants \n",
    "            Item 9A: Controls and Procedures\n",
    "            Item 9B: Other Information\n",
    "            \n",
    "      Part 3\n",
    "\n",
    "          Item 10: Directors, Executive Officers and Corporate Governance\n",
    "          Item 11: Executive Compensation\n",
    "          Item 12: Security Ownership of Certain Beneficial Owners and Management\n",
    "          Item 13: Certain Relationships and Related Transactions and Director Independence\n",
    "          Item 14: Principal Accountant Fees and Services\n",
    "\n",
    "      Part 4\n",
    "\n",
    "          Item 15: Exhibits, Financial Statement Schedules\n",
    "  \"\"\"\n",
    "\n",
    "  report_dict = None  # stores annual report as Beautiful Soup Objects\n",
    "  year = None         # year of annual report TODO: look into XBRL DocumentPeriodEndDate\n",
    "\n",
    "  def __init__(self, url:str = None, is_url:bool = True):\n",
    "     \n",
    "     # TODO: Finish Constructor\n",
    "     if is_url:\n",
    "        self.report_dict = self.parse_annual_report(url)\n",
    "        print(\"constructor finished\")\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  Accessors (Getters)\n",
    "  \"\"\"\n",
    "  def get_part(self, part_number:str):\n",
    "     key = f\"part{part_number}\"\n",
    "     return self.report_dict[key]\n",
    "  \n",
    "  def get_item(self, item_number:str):\n",
    "      key = f\"item{item_number}\"\n",
    "      return self.report_dict[key]\n",
    "  \n",
    "  def parse_annual_report(self, url: str) -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrapes An Annual Report On the SEC EDGAR Database Then Parses Through The HTML \n",
    "    And Stores Each Individual Part and Item Into A Dictionary\n",
    "\n",
    "    parameters:\n",
    "      url:str -> the url of the annual report in the SEC Directory Listing\n",
    "\n",
    "    returns:\n",
    "      dict -> dictionary whose keys are the names of the Parts (I,II,III,IV) and Items (1,2,3,etc.) \n",
    "    \"\"\"\n",
    "    \n",
    "    annual_report_dict = {} # dictionary to store all the parts of the annual report\n",
    "\n",
    "    parsed_annual_report, parsed_parts_clean = self.scrape_annual_report(url) # scrape the annual report \n",
    "    parts_dict = self.extract_parts(parsed_parts_clean)  # we have parsed parts\n",
    "\n",
    "    \n",
    "    print(\"parts dict\")\n",
    "    print(parts_dict.keys())\n",
    "\n",
    "    part_items_dict = self.extract_all_items_from_table_contents(parsed_annual_report)\n",
    "    items_dict = self.extract_all_items(parts_dict, part_items_dict)\n",
    "    print(items_dict)\n",
    "\n",
    "    return {\"full report\":parsed_annual_report, **parts_dict, **items_dict}\n",
    "    # call a function that will take the elements between 2 parts (or the last part 4)\n",
    "    # and returns a dictionary that has all the items and the corresponding BeautifulSoup \n",
    "    # Object for the elements(tags) in between!\n",
    "        \n",
    "\n",
    "  def scrape_annual_report(self, url:str) -> (BeautifulSoup, list):\n",
    "\n",
    "    \"\"\"\n",
    "    Scrapes EDGAR For An Annual Report Using The Provided URL And Stores Data In Text File.\n",
    "\n",
    "    parameters:\n",
    "      url: the url of the annual report\n",
    "    \n",
    "    returns:\n",
    "      tuple (parsed_annual_report, parsed_parts_clean)\n",
    "        parsed_annual_report: the entire html document (BeautifulSoup Object)\n",
    "        parsed_parts_clean: a list of Navigable Strings\n",
    "    \"\"\"\n",
    "\n",
    "    \"Step 1. Scrape The HTML File\"\n",
    "\n",
    "    annual_report = requests.get(url, headers={\"User-Agent\": \"bzhang14@umd.edu\"})   # sends get request to URL endpoint (html file)\n",
    "    parsed_annual_report = BeautifulSoup(annual_report.text, 'html.parser')         # parse the response using BeautifulSoup \n",
    "\n",
    "    \"Step 2. Split into Parts\"\n",
    "\n",
    "    parts = [re.compile(\"^PART.I$\", re.I), re.compile(\"^PART.II$\", re.I), \n",
    "             re.compile(\"^PART.III$\", re.I), re.compile(\"^PART.IV$\", re.I)]        # lists of parts for annual report\n",
    "    parsed_parts = parsed_annual_report.find_all(string=parts)  # list of all elements that contain any of the parts in the list above\n",
    "\n",
    "    # list of actual part seperating elements\n",
    "    # note that the the actual seperating elements are stored in spans!\n",
    "    parsed_parts_clean = [part for part in parsed_parts if part.parent.name != \"a\" and part.parent.parent.name != \"a\"]                              \n",
    "    return parsed_annual_report, parsed_parts_clean # returns tuple \n",
    "\n",
    " #############################################################################################\n",
    " ##################################### EXTRACTING PARTS ######################################\n",
    " #############################################################################################\n",
    "\n",
    "  def extract_parts(self, parsed_parts):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts The Elements Between The Parts (1,2,3,4)\n",
    "    \"\"\"\n",
    "\n",
    "    part1 = parsed_parts[0].parent.parent       # access the grand parent because the first parent is the tag\n",
    "    part2 = parsed_parts[1].parent.parent       # that wraps the text \"PART I\", this is usually the <span>\n",
    "    part3 = parsed_parts[2].parent.parent       # the tag that wraps the <span> is usually a <div>\n",
    "    part4 = parsed_parts[3].parent.parent\n",
    "\n",
    "    elements_part1_to_part2 = self.find_elements_inbetween(part1, part2)     \n",
    "    elements_part2_to_part3 = self.find_elements_inbetween(part2, part3)\n",
    "    elements_part3_to_part4 = self.find_elements_inbetween(part3, part4)\n",
    "\n",
    "    return {\"part1\":elements_part1_to_part2, \n",
    "            \"part2\":elements_part2_to_part3, \n",
    "            \"part3\":elements_part3_to_part4, \n",
    "            \"part4\":part4} # !! WARN: part 4 might not be a Beautiful Soup !!\n",
    "\n",
    "\n",
    "\n",
    "  #############################################################################################\n",
    "  ##################################### EXTRACTING ITEMS ######################################\n",
    "  #############################################################################################\n",
    "\n",
    "  def extract_all_items_from_table_contents(self, parsed_annual_report: BeautifulSoup): \n",
    "    \"\"\"\n",
    "    Extracts All The Item Names From Table Of Cotents.\n",
    "    \"\"\"\n",
    "    table_of_contents_header = parsed_annual_report.find_all(string=re.compile(\"^Table.Of.Contents$\", re.I))\n",
    "    table_of_contents_header_clean = [header for header in table_of_contents_header if header.parent.name != \"a\" and header.parent.parent.name != \"a\"]\n",
    "    parts_item_dict = {\"part1\":[], \"part2\": [], \"part3\":[], \"part4\":[]}\n",
    "\n",
    "    if table_of_contents_header_clean == None:\n",
    "      print(\"Error, no table of contents found (using the clean headers)\")\n",
    "    else:\n",
    "\n",
    "      table_of_contents = table_of_contents_header_clean[0].find_next(\"table\")\n",
    "\n",
    "    # match each item here, and assign them to the corresponding part\n",
    "    for tr in table_of_contents.find_all(\"tr\"):\n",
    "        for td in tr.find_all(\"td\"):\n",
    "          if td.string != None:\n",
    "            if re.match(re.compile(\"^Item.[1-4]{1}[A-Z]?\\.$\",re.I), td.string) != None:\n",
    "              parts_item_dict[\"part1\"].append(re.search(re.compile(\"[0-9]+[A-Z]?\", re.I),td.string).group())\n",
    "            elif re.match(re.compile(\"^Item.[5-9]{1}[A-Z]?\\.$\",re.I), td.string) != None:\n",
    "              parts_item_dict[\"part2\"].append(re.search(re.compile(\"[0-9]+[A-Z]?\", re.I),td.string).group())\n",
    "            elif re.match(re.compile(\"^Item.1[0-4]{1}[A-Z]?\\.$\",re.I), td.string) != None:\n",
    "              parts_item_dict[\"part3\"].append(re.search(re.compile(\"[0-9]+[A-Z]?\", re.I),td.string).group())\n",
    "            elif re.match(re.compile(\"^Item.1[5-6]{1}[A-Z]?\\.$\",re.I), td.string) != None:\n",
    "              parts_item_dict[\"part4\"].append(re.search(re.compile(\"[0-9]+[A-Z]?\", re.I),td.string).group())\n",
    "\n",
    "    return parts_item_dict\n",
    "\n",
    "\n",
    "\n",
    "  def extract_all_items(self, part_elements_dict: dict, part_items_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Wrapper Function That Makes Calls To extract_items() To Extract Items From All Parts \n",
    "    Of The Annual Report.\n",
    "\n",
    "    parameters: \n",
    "      part_elements_list -> list of all elements for every part\n",
    "\n",
    "    returns:\n",
    "      dict ->  dictionary with the following structure \n",
    "        1st layer (key: itme name, value: BeautifulSoup object )\n",
    "    \"\"\"\n",
    "    print(\"part items dict\")\n",
    "    print(part_items_dict)\n",
    "    item_dict = {}\n",
    "    for part in range(1, 3):  # NOTE: Currently iterating through Part 1 and 2 only\n",
    "       part_name = f\"part{part}\"\n",
    "       print(f\"part name: {part_name}\")\n",
    "       parts_item_dict = self.extract_items(part_elements_dict[part_name], part_items_dict[part_name])\n",
    "       #print(parts_item_dict)\n",
    "       item_dict = {**item_dict, **parts_item_dict}\n",
    "\n",
    "\n",
    "    return item_dict\n",
    "\n",
    "\n",
    "  def extract_items(self, part_elements: BeautifulSoup, items: list) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the Items Within A Specific Part Of The Annual Report.\n",
    "\n",
    "    parameters:\n",
    "      parts_element:BeautifulSoup -> all of the elements for a specific part of the 10K\n",
    "      part_number:int -> the number of the part \n",
    "    returns:\n",
    "      dict -> key value pair (key: name of item, value: BeautifulSoup object of all elements in item)\n",
    "    \"\"\"\n",
    "\n",
    "    items_dict = {}\n",
    "    parsed_items = []\n",
    "    for item in items:\n",
    "    \n",
    "         \n",
    "   \n",
    "      regex = re.compile(f\"^Item.{item}\\.?$\", re.I)\n",
    "      item_elements = list(part_elements.find_all(string=regex))\n",
    "\n",
    "      if item == \"1A\":\n",
    "         for element in item_elements:\n",
    "            print(element.parent.parent.name)\n",
    "\n",
    "      if len(item_elements) == 0:\n",
    "          print(f\"no element found for item: item{item}\")\n",
    "      else:\n",
    "        parsed_items.extend(item_elements)  \n",
    "\n",
    "    print(parsed_items)\n",
    "\n",
    "    # list of actual part seperating elements\n",
    "    # note that the the actual seperating elements are stored in spans!\n",
    "    # these are just navigable strings\n",
    "    print(len(parsed_items))\n",
    "    parsed_items_clean = [part for part in parsed_items if part.parent.name != \"a\" and\n",
    "                          part.parent.parent.name != \"a\" \n",
    "                          and len(list(part.parent.next_siblings)) == 0\n",
    "                          and len(list(part.parent.previous_siblings)) == 0]   \n",
    "\n",
    "    print(len(parsed_items_clean))\n",
    "    print(\"parsed items clean\")\n",
    "    print(parsed_items_clean)\n",
    "    # iterate through all of the items (expect for the last)\n",
    "    for item_index in range(0, len(parsed_items_clean) - 1):\n",
    "        start_item = self.find_tag_with_siblings(parsed_items_clean[item_index])\n",
    "        end_item = self.find_tag_with_siblings(parsed_items_clean[item_index + 1])\n",
    "        key = items[item_index]\n",
    "\n",
    "        items_dict[key] = self.find_elements_inbetween(start_item, end_item)\n",
    "  \n",
    "    # TODO: figure out how to parse the last item in the part!!!\n",
    "\n",
    "    return items_dict\n",
    "  \n",
    "\n",
    "  #############################################################################################\n",
    "  ##################################### HELPER FUNCTIONS ######################################\n",
    "  #############################################################################################\n",
    "\n",
    "\n",
    "  def find_elements_inbetween(self, element_1, element_2) -> BeautifulSoup:\n",
    "\n",
    "    \"\"\"\n",
    "    Useful Function To Find All The Elements Between Two Elements \n",
    "    \"\"\"\n",
    "    element_list = []      # list that stores bs4.element.Tag\n",
    "    \n",
    "    soup = BeautifulSoup(str(element_1), \"html.parser\")\n",
    "    element_1_in_soup = soup.find(element_1.name)\n",
    "\n",
    "    for element in element_1.next_siblings:                 # iterate through the all of the elements that come after \n",
    "        element_list.append(copy.copy(element))             # element_1, this is in element_1.next_siblings\n",
    "\n",
    "        if element == element_2:                            # if the second element is encountered then break out of loop\n",
    "            break\n",
    "    \n",
    "    for element in element_list[::-1]:\n",
    "\n",
    "        element_1_in_soup.insert_after(element)\n",
    "    \n",
    "    return soup\n",
    "\n",
    "\n",
    "  def find_tag_with_siblings(self, tag):\n",
    "    curr_tag = tag\n",
    "\n",
    "    while len(list(curr_tag.next_siblings)) == 0:\n",
    "       curr_tag = curr_tag.parent\n",
    "\n",
    "    return curr_tag\n",
    "\n",
    "\n",
    "  def extract_specific_item(self, elements: BeautifulSoup, part_num:int, item:re.Pattern):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract A Specific Item For A Specific Part Of The Annual Report.\n",
    "    \"\"\"\n",
    "\n",
    "    items_list = elements.find_all(string=item)\n",
    "    items_list_cleaned = [item_element for item_element in items_list if item_element.parent != \"a\"]\n",
    "\n",
    "  #############################################################################################\n",
    "  ############################## EXTRACTING FINANCIAL STATEMENTS ##############################\n",
    "  #############################################################################################\n",
    "  def extract_income_statement(self):\n",
    "     \n",
    "    \"\"\"\n",
    "    Extracts The Income Statement From Part 2, Item 8 Financal Statements Of The Annual Report.\n",
    "\n",
    "    parameters: None\n",
    "    returns: ??? \n",
    "    \"\"\"\n",
    "    item8 = self.get_item(\"8\")\n",
    "\n",
    "    # possible names for the income statement in annual report\n",
    "    statement_names = [re.compile(\"^Consolidated Statements of $\", re.I), \n",
    "                       re.compile(\"^Consolidated Statements of Income\", re.I),\n",
    "                       re.compile(\"^Consolidated Statements of Operations\", re.I)]  \n",
    "\n",
    "    # loop through all the possible names for the Income Statement and break\n",
    "    # from loop when one is found!\n",
    "    for statement_name in statement_names:\n",
    "        elements = item8.find_all(string=statement_name)\n",
    "        print(elements)\n",
    "        if len(list(elements)) != 0:\n",
    "            break\n",
    "        \n",
    "    years = []\n",
    "    table = elements[0].find_next(\"table\")      # find the income statement table \n",
    "                                                # (we assume its the table after the span element)\n",
    "\n",
    "    \"data structures\"\n",
    "    xbrl_dictionary = {}                        # dictionary to define xbrl concepts\n",
    "                                                # key: name in Income Statement, value: XBRL concept name\n",
    "    \n",
    "    metric_values = {}                          # dictionary that stores the metric as reported in the income statement\n",
    "                                                # key: name in Income Statement, value: Value of Metric for the year\n",
    "    \n",
    "    statement_name_list = []                    # ordered list of metrics reported in Income Statement\n",
    "\n",
    "    for tr in table.findAll(\"tr\"):                          # iterate through the rows of the table\n",
    "      for td in tr:                                       # iterate through the entries of the table row\n",
    "\n",
    "\n",
    "        # matches with not None String or $ sign\n",
    "        if td.string != None and td.string != \"$\":   \n",
    "\n",
    "          # match with year\n",
    "          if re.match(re.compile(\".*[0-9]{4}$\"), td.string) != None:\n",
    "            years.append(td.string)\n",
    "\n",
    "          # matches with a value for a reported metric if XBRL doesn't exist\n",
    "          elif re.match(re.compile(\"^\\(?[0-9]{1,3}(,[0-9]{3})*\\)?$\"), td.string) != None:\n",
    "            if income_statement_name not in statement_name_list:\n",
    "              metric_values[income_statement_name] = [td.string]\n",
    "            else:\n",
    "              metric_values[income_statement_name].append(td.string)\n",
    "        \n",
    "          # otherwise this should be the name of a value in the income statement\n",
    "          else:\n",
    "            income_statement_name = td.string  # define income_statment_name here\n",
    "\n",
    "        # matches with any XBRL element\n",
    "        elif td.find(\"ix:nonfraction\") != None: \n",
    "          xbrl_element = td.find(\"ix:nonfraction\")  # xbrl_element is the html element <ix:nonfraction>\n",
    "          xbrl_concept_name = xbrl_element[\"name\"]  # xbrl_element[\"name\"] is the value of the name attribute in the XBRL element tag                                                       \n",
    "          xbrl_concept_value = xbrl_element.string  # the actual value of the XBRL concept\n",
    "\n",
    "          if income_statement_name not in xbrl_dictionary.keys():\n",
    "              xbrl_dictionary[income_statement_name] = xbrl_concept_name   # store the concept name in dictionary\n",
    "              statement_name_list.append(income_statement_name)   # adds the metric name as reported to the list \n",
    "              metric_values[income_statement_name] = []           # create initial key value pair\n",
    "\n",
    "          metric_values[income_statement_name].append(xbrl_concept_value)\n",
    "\n",
    "          #print(td.find(\"ix:nonfraction\")[\"name\"])       # print the name of the (XBRL) concept \n",
    "          #print(td.find(\"ix:nonfraction\").string)        # print the value of the (XBRL) element\n",
    "\n",
    "    \n",
    "\n",
    "    return xbrl_dictionary, metric_values, statement_name_list, years\n",
    "  \n",
    "\n",
    "  def find_item8(self, part2):\n",
    "    item_8 = part2.find_all(string=re.compile(\"Item.8..Financial.Statements\", re.I)) # note ignore case\n",
    "    return item_8\n",
    "  \n",
    "  def find_income_statements(self, cik:str):\n",
    "    \n",
    "    urls = ws.json_submission_scraper(cik, \"10-K\")  # get all the URLS of the 10-Ks\n",
    "    \n",
    "    count = 1\n",
    "    for url in urls:\n",
    "      \n",
    "      parsed_annual_report, parsed_parts_clean = self.scrape_annual_report(url)\n",
    "      parts_list = self.extract_parts(parsed_parts_clean)\n",
    "      item8 = self.find_item8(parts_list[1])\n",
    "      xbrl_dictionary , metric_values, statement_name_list = income_statement(item8)\n",
    "      \n",
    "      xbrl_dictionary_string = \"\"\n",
    "      for key,value in xbrl_dictionary.items:\n",
    "         xbrl_dictionary_string += f\"{key}:{value}\\n\"\n",
    "\n",
    "      with open(f\"../data/company data/LULU/annual report {count}.txt\", \"w+\") as file:\n",
    "        file.write(xbrl_dictionary_string)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts dict\n",
      "dict_keys(['part1', 'part2', 'part3', 'part4'])\n",
      "part items dict\n",
      "{'part1': ['1', '1A', '1B', '2', '3', '4'], 'part2': ['5', '6', '7', '7A', '8', '9', '9A', '9B', '9C'], 'part3': ['10', '11', '12', '13', '14'], 'part4': ['15', '16']}\n",
      "part name: part1\n",
      "no element found for item: item1\n",
      "no element found for item: item1A\n",
      "no element found for item: item1B\n",
      "no element found for item: item2\n",
      "no element found for item: item3\n",
      "no element found for item: item4\n",
      "[]\n",
      "0\n",
      "0\n",
      "parsed items clean\n",
      "[]\n",
      "part name: part2\n",
      "no element found for item: item5\n",
      "no element found for item: item6\n",
      "no element found for item: item7\n",
      "no element found for item: item7A\n",
      "no element found for item: item8\n",
      "no element found for item: item9\n",
      "no element found for item: item9A\n",
      "no element found for item: item9B\n",
      "no element found for item: item9C\n",
      "[]\n",
      "0\n",
      "0\n",
      "parsed items clean\n",
      "[]\n",
      "{}\n",
      "constructor finished\n"
     ]
    }
   ],
   "source": [
    "af_10k = AnnualReport(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(af_10k.report_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(re.compile(\"[0-9]\"),\"m1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbrl_dictionary, metric_values, statement_name_list, years = af_10k.extract_income_statement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"1\"\n",
    "regex = re.compile(f\"^Item.{item}\", re.I)\n",
    "re.match(regex, \"Wow Item 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vfc_10k.get_item(\"1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(re.compile(\".*[0-9]{4}$\"),\"Fiscal 2020\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
